import os
import subprocess
import sys
import threading
import time
import streamlit as st
# try:
#     from langchain_teddynote import logging
# except ModuleNotFoundError as e:
#     subprocess.Popen([f'{sys.executable} -m pip install git+https://${{GITHUB_TOKEN}}@github.com/teddylee777/langchain-teddynote.git'], shell=True)
#     time.sleep(90)
from langchain_ollama import ChatOllama
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate


from langchain_core.messages.chat import ChatMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableLambda, RunnablePassthrough
from langchain_openai import ChatOpenAI
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.document_loaders import TextLoader
from langchain_community.document_loaders import PyMuPDFLoader

from modules.utils import initialize_logging, get_model_list
# from task_llm.task_manager import task_execute_llm





# ë¡œê·¸ ì„¤ì •
initialize_logging("streamlit", set_enable=False)

st.set_page_config(layout="wide")
st.html("""
    <style>
        html, body {
            font-size: 14px;
        }
    </style>
    """
)


st.title("E-ì•½ì€ìš” ìë£Œ ìƒì„±")
st.markdown(
    """
E ì•½ì€ìš” ìë£Œ ìƒì„± ì‘ì—…
"""
)
   

# ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ ë° ì´ˆê¸°í™”
models = get_model_list()

# ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼ ì¶”ê°€
with st.sidebar:
    # ëª¨ë¸ ì„ íƒ ë²„íŠ¼
    selected_model_main = st.selectbox("LLM ì„ íƒ", models, index=0)
    # í”„ë¡¬í”„íŠ¸ ì„ íƒ 
    selected_prompt = st.selectbox(" í”„ë¡¬í”„íŠ¸ ì„ íƒ", ["ê¸°ë³¸ëª¨ë“œ", "ì•½ì •ë³´"], index=0)






# ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… í•¨ìˆ˜ (ë¬´í•œ ë£¨í”„ ì‘ì—…)
def background_task():
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìˆ˜í–‰í•  ì‘ì—… (ì˜ˆ: ë°ì´í„°ë² ì´ìŠ¤ í™•ì¸, API í˜¸ì¶œ ë“±)"""
    current_thread_id = threading.get_ident()  # í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ìŠ¤ë ˆë“œ ID
    print(f"ğŸ§µ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹œì‘ - ìŠ¤ë ˆë“œ ID: {current_thread_id}   session thread_id : {st.session_state.get('thread_id')}")
    # st.session_state['thread_id'] = current_thread_id  # ìŠ¤ë ˆë“œ ID ì €ì¥
    
    

    # while st.session_state['thread_running']:
    #     # if st.session_state.get('thread_id') != current_thread_id:
    #     #     print(f"ğŸ›‘ í˜„ì¬ ìŠ¤ë ˆë“œ {current_thread_id}ê°€ ì¢…ë£Œë©ë‹ˆë‹¤. ìƒˆë¡œìš´ ìŠ¤ë ˆë“œê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.")
    #     #     break  # ìŠ¤ë ˆë“œê°€ ì¤‘ë³µ ì‹¤í–‰ë˜ì§€ ì•Šë„ë¡ ì¤‘ë‹¨


    #     st.session_state['last_run'] = time.strftime("%Y-%m-%d %H:%M:%S")
    #     print(f"ğŸ”„ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹¤í–‰ ì¤‘... í˜„ì¬ ì‹œê°„: {st.session_state.get('last_run')}")
    #     print(f"ğŸ”„ st.session_state.get('llm_running') : {st.session_state.get('llm_running')}")

    #     # LLM ì‘ì—…ì´ ì‹¤í–‰ ì¤‘ì´ì§€ ì•Šìœ¼ë©´ ì‘ì—… ì‹œì‘
    #     if not st.session_state.get('llm_running', False): 
    #         task_execute_llm()

    #     time.sleep(10)  # 10ì´ˆë§ˆë‹¤ ë°˜ë³µ


# ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹¤í–‰ ì—¬ë¶€ í™•ì¸ ë° ì‹œì‘
# if 'thread_running' not in st.session_state:
    
#     st.session_state['llm_running'] = False  # LLM ì‹¤í–‰ í”Œë˜ê·¸
#     background_thread = threading.Thread(target=background_task, daemon=True)
#     background_thread.start()
#     st.session_state['thread_running'] = True
#     st.session_state['thread_id'] = threading.get_ident()    # ìŠ¤ë ˆë“œ ì‹¤í–‰ í”Œë˜ê·¸ - thread_id

#     st.write("ğŸš€ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤.")


# if st.session_state['thread_running']:
#     st.write(f"ğŸš€ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì§„í–‰ì¤‘.")
# else:
#     st.write("ğŸš€ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…ì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")

# Streamlit ë©”ì¸ UI
# st.title("ğŸ“‹ Streamlit ì•± - ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ìˆ˜í–‰ ì¤‘")
# st.write(f"ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…ì˜ ë§ˆì§€ë§‰ ì‹¤í–‰ ì‹œê°„: {st.session_state.get('last_run', 'ì‹¤í–‰ ì¤‘ì´ ì•„ë‹˜')}")



    

    




